{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ebeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "        \"pyannote/voice-activity-detection\",\n",
    "        use_auth_token=HF_TOKEN\n",
    "    )\n",
    "\n",
    "pipeline = pipeline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the audio file\n",
    "audio_file = \"test.wav\"       ###########\n",
    "output = pipeline(audio_file)\n",
    "\n",
    "print(f\"Processing {audio_file} on {device}\")\n",
    "print(\"Voice activity segments:\")\n",
    "\n",
    "# Get all speech segments\n",
    "speech_segments = list(output.get_timeline().support())\n",
    "\n",
    "for i, speech in enumerate(speech_segments):\n",
    "    # active speech between speech.start and speech.end\n",
    "    print(f\"Segment {i+1}: Speech from {speech.start:.2f}s to {speech.end:.2f}s (duration: {speech.duration:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2d9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "def split_audio_by_segments(audio_path, segments, output_dir=\"output_segments\"):\n",
    "    \"\"\"\n",
    "    Split an audio file into multiple files based on speech segments\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    audio_path: str\n",
    "        Path to the input audio file\n",
    "    segments: list\n",
    "        List of speech segments (with start and end attributes)\n",
    "    output_dir: str\n",
    "        Directory to save the output segments\n",
    "    \"\"\"\n",
    "    # Clear the output directory if it exists\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    \n",
    "    # Extract each segment\n",
    "    for i, segment in enumerate(segments):\n",
    "        # Convert seconds to milliseconds\n",
    "        start_ms = int(segment.start * 1000)\n",
    "        end_ms = int(segment.end * 1000)\n",
    "        \n",
    "        # Extract segment\n",
    "        segment_audio = audio[start_ms:end_ms]\n",
    "        \n",
    "        # Generate output filename\n",
    "        filename = os.path.basename(audio_path)\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        output_path = os.path.join(output_dir, f\"{name}_segment_{i+1:04d}_{start_ms:08d}ms-{end_ms:08d}ms{ext}\")\n",
    "        \n",
    "        # Export segment\n",
    "        segment_audio.export(output_path, format=ext.replace('.', ''))\n",
    "        print(f\"Saved segment {i+1} to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_audio_by_segments(audio_file, speech_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def play_audio(file_path, sr=None):\n",
    "    \"\"\"\n",
    "    Play an audio file in a Jupyter notebook.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the audio file to play\n",
    "    sr : int, optional\n",
    "        Sample rate to load the audio with. If None, uses the file's native sample rate.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Audio widget that can be played in the notebook\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> play_audio('path/to/audio.wav')\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    \n",
    "    # Return an audio widget to play the sound\n",
    "    audio_widget = Audio(data=y, rate=sr)\n",
    "    display(audio_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca03ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97046f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "audio_dir = \"./output_segments/\"\n",
    "\n",
    "audio_files = os.listdir(audio_dir)\n",
    "audio_files.sort()\n",
    "\n",
    "n_clips = 3\n",
    "\n",
    "for fname in audio_files[0:n_clips]:\n",
    "    play_audio(audio_dir + fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28decb66",
   "metadata": {},
   "source": [
    "## **MFA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8072ca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Folder target dibuat: ../data/raw/audio\n",
      "üîÑ Memindahkan isi dari folder: audio_part_0/audio...\n",
      "‚úÖ Selesai: audio_part_0 dan isinya telah bersih dihapus.\n",
      "üîÑ Memindahkan isi dari folder: audio_part_1/audio...\n",
      "‚úÖ Selesai: audio_part_1 dan isinya telah bersih dihapus.\n",
      "üîÑ Memindahkan isi dari folder: audio_part_2/audio...\n",
      "‚úÖ Selesai: audio_part_2 dan isinya telah bersih dihapus.\n",
      "==================================================\n",
      "üéØ PROSES PENGGABUNGAN BERSARANG SELESAI!\n",
      "Total file .flac dipindahkan: 95572\n",
      "Semua file audio sekarang rapi di dalam: ../data/raw/audio\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def combine_nested_audio_folders(base_dir):\n",
    "    \"\"\"\n",
    "    Menggabungkan isi dari audio_part_0/audio, audio_part_1/audio, dst.\n",
    "    ke dalam satu folder utama bernama 'audio' di base_dir.\n",
    "    \"\"\"\n",
    "    # 1. Tentukan target folder utama (data/raw/audio)\n",
    "    target_dir = os.path.join(base_dir, \"audio\")\n",
    "    \n",
    "    # Buat folder target jika belum ada\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "        print(f\"üìÅ Folder target dibuat: {target_dir}\")\n",
    "\n",
    "    # 2. Daftar folder utama yang akan digabung\n",
    "    source_folders = [\"audio_part_0\", \"audio_part_1\", \"audio_part_2\"]\n",
    "    total_dipindah = 0\n",
    "\n",
    "    for folder_name in source_folders:\n",
    "        # PERUBAHAN DI SINI: Kita menargetkan sub-folder 'audio' di dalamnya\n",
    "        nested_source_dir = os.path.join(base_dir, folder_name, \"audio\")\n",
    "        \n",
    "        # Cek apakah sub-folder sumber benar-benar ada\n",
    "        if not os.path.exists(nested_source_dir):\n",
    "            print(f\"‚ö†Ô∏è Melewati {folder_name}/audio: Folder tidak ditemukan.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"üîÑ Memindahkan isi dari folder: {folder_name}/audio...\")\n",
    "        \n",
    "        # 3. Pindahkan setiap file dari sub-folder sumber ke folder target utama\n",
    "        for filename in os.listdir(nested_source_dir):\n",
    "            source_file = os.path.join(nested_source_dir, filename)\n",
    "            target_file = os.path.join(target_dir, filename)\n",
    "\n",
    "            if os.path.isfile(source_file):\n",
    "                shutil.move(source_file, target_file)\n",
    "                total_dipindah += 1\n",
    "        \n",
    "        # 4. Bersihkan jejak: Hapus sub-folder 'audio', lalu folder utamanya\n",
    "        try:\n",
    "            os.rmdir(nested_source_dir) # Hapus direktori dalam (audio)\n",
    "            \n",
    "            parent_dir = os.path.join(base_dir, folder_name)\n",
    "            os.rmdir(parent_dir)        # Hapus direktori luar (audio_part_X)\n",
    "            \n",
    "            print(f\"‚úÖ Selesai: {folder_name} dan isinya telah bersih dihapus.\")\n",
    "        except OSError:\n",
    "            print(f\"‚ö†Ô∏è Perhatian: Gagal menghapus sisa folder di {folder_name}. Mungkin ada file lain selain audio.\")\n",
    "\n",
    "    print(\"==================================================\")\n",
    "    print(f\"üéØ PROSES PENGGABUNGAN BERSARANG SELESAI!\")\n",
    "    print(f\"Total file .flac dipindahkan: {total_dipindah}\")\n",
    "    print(f\"Semua file audio sekarang rapi di dalam: {target_dir}\")\n",
    "    print(\"==================================================\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Direktori tempat script dijalankan (sejajar dengan folder audio_part_X)\n",
    "    BASE_DIRECTORY = \"../data/raw/\" \n",
    "    \n",
    "    combine_nested_audio_folders(BASE_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# import re\n",
    "\n",
    "# def prepare_mfa_data(jsonl_path):\n",
    "#     \"\"\"\n",
    "#     Membaca file JSONL dan membuat file .txt berdampingan dengan file audio \n",
    "#     untuk persiapan dataset Montreal Forced Aligner (MFA).\n",
    "#     \"\"\"\n",
    "#     print(f\"Membaca dataset dari: {jsonl_path}...\")\n",
    "    \n",
    "#     sukses = 0\n",
    "#     gagal = 0\n",
    "\n",
    "#     with open(jsonl_path, 'r', encoding='utf-8') as file:\n",
    "#         for line in file:\n",
    "#             try:\n",
    "#                 # 1. Parsing baris JSON\n",
    "#                 data = json.loads(line)\n",
    "#                 audio_path = data['audio_path']  # Contoh: \"audio/U_00003c3ae1c35c6f.flac\"\n",
    "#                 teks_asli = data['orthographic_text']\n",
    "\n",
    "#                 # 2. Membersihkan teks (MFA benci tanda baca)\n",
    "#                 # Hanya menyisakan huruf (a-z) dan spasi\n",
    "#                 teks_bersih = re.sub(r'[^a-zA-Z\\s\\']', '', teks_asli).lower().strip()\n",
    "\n",
    "#                 # 3. Menentukan jalur file .txt output\n",
    "#                 # Mengganti ekstensi .flac menjadi .txt\n",
    "#                 txt_path = os.path.splitext(audio_path)[0] + \".txt\"\n",
    "\n",
    "#                 # 4. Membuat file .txt berdampingan dengan file audio\n",
    "#                 with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "#                     txt_file.write(teks_bersih)\n",
    "                \n",
    "#                 sukses += 1\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Gagal memproses baris: {line[:50]}... Error: {e}\")\n",
    "#                 gagal += 1\n",
    "\n",
    "#     print(\"==================================================\")\n",
    "#     print(\"PROSES SELESAI!\")\n",
    "#     print(f\"Berhasil membuat: {sukses} file .txt\")\n",
    "#     if gagal > 0:\n",
    "#         print(f\"Gagal memproses : {gagal} baris\")\n",
    "#     print(\"==================================================\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Masukkan nama file JSONL Anda di sini\n",
    "#     FILE_JSONL = \"../data/raw/train_word_transcripts.jsonl\"\n",
    "    \n",
    "#     # Eksekusi fungsi\n",
    "#     prepare_mfa_data(FILE_JSONL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d4f772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membaca dataset dari: ../data/raw/train_word_transcripts.jsonl...\n",
      "\n",
      "Memulai patroli audit folder audio...\n",
      "==================================================\n",
      "üéØ PROSES PERSIAPAN & AUDIT MFA SELESAI!\n",
      "File .txt berhasil dibuat   : 95572\n",
      "Baris JSON gagal diproses   : 0\n",
      "Audio yatim dikarantina     : 0 file (Dipindahkan ke folder 'audio_karantina')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "def prepare_and_audit_mfa_data(jsonl_path, base_audio_dir):\n",
    "    \"\"\"\n",
    "    1. Membaca JSONL dan membuat file .txt\n",
    "    2. Mengaudit folder audio dan menyingkirkan file .flac yang tidak punya pasangan .txt\n",
    "    \"\"\"\n",
    "    print(f\"Membaca dataset dari: {jsonl_path}...\")\n",
    "    \n",
    "    sukses = 0\n",
    "    gagal = 0\n",
    "\n",
    "    # ==========================================\n",
    "    # FASE 1: INJEKSI TEKS\n",
    "    # ==========================================\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                # Path asli dari JSONL, misal: \"audio/U_000.flac\"\n",
    "                audio_path_rel = data['audio_path'] \n",
    "                teks_asli = data['orthographic_text']\n",
    "\n",
    "                # Bersihkan teks (mengizinkan huruf, spasi, dan apostrof)\n",
    "                teks_bersih = re.sub(r'[^a-zA-Z\\s\\']', '', teks_asli).lower().strip()\n",
    "\n",
    "                # Gabungkan dengan base directory tempat script berjalan\n",
    "                full_flac_path = os.path.join(os.path.dirname(jsonl_path), audio_path_rel)\n",
    "                txt_path = os.path.splitext(full_flac_path)[0] + \".txt\"\n",
    "\n",
    "                # Pastikan file flac-nya benar-benar ada sebelum membuat txt\n",
    "                if os.path.exists(full_flac_path):\n",
    "                    with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "                        txt_file.write(teks_bersih)\n",
    "                    sukses += 1\n",
    "                else:\n",
    "                    # Flac tidak ada di hard disk (mungkin korup saat download)\n",
    "                    gagal += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                gagal += 1\n",
    "\n",
    "    # ==========================================\n",
    "    # FASE 2: PATROLI & KARANTINA (AUDIT)\n",
    "    # ==========================================\n",
    "    print(\"\\nMemulai patroli audit folder audio...\")\n",
    "    folder_audio = os.path.join(os.path.dirname(jsonl_path), base_audio_dir)\n",
    "    folder_karantina = os.path.join(os.path.dirname(jsonl_path), \"audio_karantina\")\n",
    "    \n",
    "    flac_yatim = 0\n",
    "    \n",
    "    # Cek setiap file di folder audio\n",
    "    if os.path.exists(folder_audio):\n",
    "        for filename in os.listdir(folder_audio):\n",
    "            if filename.endswith(\".flac\"):\n",
    "                jalur_flac = os.path.join(folder_audio, filename)\n",
    "                jalur_txt = os.path.splitext(jalur_flac)[0] + \".txt\"\n",
    "                \n",
    "                # Jika tidak ada file txt pasangannya\n",
    "                if not os.path.exists(jalur_txt):\n",
    "                    # Buat folder karantina jika belum ada\n",
    "                    os.makedirs(folder_karantina, exist_ok=True)\n",
    "                    \n",
    "                    # Pindahkan file flac tersebut ke karantina\n",
    "                    shutil.move(jalur_flac, os.path.join(folder_karantina, filename))\n",
    "                    flac_yatim += 1\n",
    "\n",
    "    # ==========================================\n",
    "    # LAPORAN AKHIR\n",
    "    # ==========================================\n",
    "    print(\"==================================================\")\n",
    "    print(\"üéØ PROSES PERSIAPAN & AUDIT MFA SELESAI!\")\n",
    "    print(f\"File .txt berhasil dibuat   : {sukses}\")\n",
    "    print(f\"Baris JSON gagal diproses   : {gagal}\")\n",
    "    print(f\"Audio yatim dikarantina     : {flac_yatim} file (Dipindahkan ke folder 'audio_karantina')\")\n",
    "    print(\"==================================================\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sesuaikan path ke file JSONL Anda\n",
    "    FILE_JSONL = \"../data/raw/train_word_transcripts.jsonl\"\n",
    "    \n",
    "    # Folder target di mana audio digabungkan (relatif terhadap letak JSONL)\n",
    "    BASE_AUDIO_DIR = \"audio\" \n",
    "    \n",
    "    prepare_and_audit_mfa_data(FILE_JSONL, BASE_AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c65889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio\t      noise_part_1\t\t       submission_format_z2HCh3r.jsonl\n",
      "noise_part_0  submission_format_aqPHQ8m.jsonl  train_word_transcripts.jsonl\n"
     ]
    }
   ],
   "source": [
    "# !ls ../data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw/audio/U_00003c3ae1c35c6f.flac\n",
      "../data/raw/audio/U_00003c3ae1c35c6f.txt\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# import os\n",
    "# import re\n",
    "# import shutil\n",
    "\n",
    "# jsonl_path = '../data/raw/train_word_transcripts.jsonl'\n",
    "\n",
    "# with open(jsonl_path, 'r', encoding='utf-8') as file:\n",
    "#     for line in file:\n",
    "#         try:\n",
    "#             data = json.loads(line)\n",
    "#             # Path asli dari JSONL, misal: \"audio/U_000.flac\"\n",
    "#             audio_path_rel = data['audio_path'] \n",
    "#             teks_asli = data['orthographic_text']\n",
    "\n",
    "#             # Bersihkan teks (mengizinkan huruf, spasi, dan apostrof)\n",
    "#             teks_bersih = re.sub(r'[^a-zA-Z\\s\\']', '', teks_asli).lower().strip()\n",
    "\n",
    "#             # Gabungkan dengan base directory tempat script berjalan\n",
    "#             full_flac_path = os.path.join(os.path.dirname(jsonl_path), audio_path_rel)\n",
    "#             txt_path = os.path.splitext(full_flac_path)[0] + \".txt\"\n",
    "\n",
    "#             print(full_flac_path)\n",
    "#             print(txt_path)\n",
    "\n",
    "#             break\n",
    "\n",
    "#             # # Pastikan file flac-nya benar-benar ada sebelum membuat txt\n",
    "#             # if os.path.exists(full_flac_path):\n",
    "#             #     with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "#             #         txt_file.write(teks_bersih)\n",
    "#             #     sukses += 1\n",
    "#             # else:\n",
    "#             #     # Flac tidak ada di hard disk (mungkin korup saat download)\n",
    "#             #     gagal += 1\n",
    "\n",
    "#         except Exception as e:\n",
    "#             gagal += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f10aa3",
   "metadata": {},
   "source": [
    "## **Splitting Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e387254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üî™ MEMULAI OPERASI PEMBEDAHAN DATASET (DATA SPLIT) üî™\n",
      "==================================================\n",
      "[Logistik] Membaca file induk: ../data/raw/train_word_transcripts.jsonl\n",
      "[Logistik] Total amunisi ditemukan: 95572 baris.\n",
      "\n",
      "[Laporan] Operasi Pembedahan Selesai:\n",
      "‚úÖ TRAIN SET : 76457 data (80.0%) -> ../data/processed/train_split.jsonl\n",
      "‚úÖ VAL SET   : 9557 data (10.0%) -> ../data/processed/val_split.jsonl\n",
      "‚úÖ TEST SET  : 9558 data (10.0%) -> ../data/processed/test_split.jsonl\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_jsonl_dataset(\n",
    "        input_file, \n",
    "        output_dir, \n",
    "        train_ratio=0.8, \n",
    "        val_ratio=0.1, \n",
    "        random_seed=42\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Membedah satu file JSONL besar menjadi 3 file terpisah: Train, Val, dan Test.\n",
    "    \"\"\"\n",
    "    print(\"==================================================\")\n",
    "    print(\"üî™ MEMULAI OPERASI PEMBEDAHAN DATASET (DATA SPLIT) üî™\")\n",
    "    print(\"==================================================\")\n",
    "    \n",
    "    # 1. Pastikan folder output tersedia\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 2. Muat seluruh data ke dalam memori\n",
    "    print(f\"[Logistik] Membaca file induk: {input_file}\")\n",
    "    df = pd.read_json(input_file, lines=True)\n",
    "    total_data = len(df)\n",
    "    print(f\"[Logistik] Total amunisi ditemukan: {total_data} baris.\")\n",
    "\n",
    "    # 3. Taktik Pembedahan Tahap 1: Pisahkan Train dan (Val + Test)\n",
    "    # Kita kunci random_state agar jika script ini di-run ulang, \n",
    "    # file audionya tidak berpindah-pindah folder (Reproducible).\n",
    "    train_df, temp_df = train_test_split(\n",
    "        df, \n",
    "        train_size=train_ratio, \n",
    "        random_state=random_seed\n",
    "    )\n",
    "\n",
    "    # 4. Taktik Pembedahan Tahap 2: Pecah sisa data menjadi Val dan Test\n",
    "    # Jika train_ratio = 0.8, maka sisa temp_df adalah 0.2.\n",
    "    # Untuk mendapatkan Val 0.1 dan Test 0.1, kita belah temp_df tepat 50:50.\n",
    "    test_ratio_relative = (1.0 - train_ratio - val_ratio) / (1.0 - train_ratio)\n",
    "    \n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df, \n",
    "        test_size=test_ratio_relative, \n",
    "        random_state=random_seed\n",
    "    )\n",
    "\n",
    "    # 5. Ekspor Data ke JSONL Baru\n",
    "    train_path = os.path.join(output_dir, \"train_split.jsonl\")\n",
    "    val_path = os.path.join(output_dir, \"val_split.jsonl\")\n",
    "    test_path = os.path.join(output_dir, \"test_split.jsonl\")\n",
    "\n",
    "    # orient='records', lines=True memastikan format output persis seperti input aslinya\n",
    "    train_df.to_json(train_path, orient='records', lines=True)\n",
    "    val_df.to_json(val_path, orient='records', lines=True)\n",
    "    test_df.to_json(test_path, orient='records', lines=True)\n",
    "\n",
    "    # 6. Laporan Intelijen Akhir\n",
    "    print(\"\\n[Laporan] Operasi Pembedahan Selesai:\")\n",
    "    print(f\"‚úÖ TRAIN SET : {len(train_df)} data ({len(train_df)/total_data*100:.1f}%) -> {train_path}\")\n",
    "    print(f\"‚úÖ VAL SET   : {len(val_df)} data ({len(val_df)/total_data*100:.1f}%) -> {val_path}\")\n",
    "    print(f\"‚úÖ TEST SET  : {len(test_df)} data ({len(test_df)/total_data*100:.1f}%) -> {test_path}\")\n",
    "    print(\"==================================================\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sesuaikan path ini dengan lokasi file Anda di Ubuntu\n",
    "    FILE_INPUT_ASLI = \"../data/raw/train_word_transcripts.jsonl\"\n",
    "    FOLDER_OUTPUT = \"../data/processed\"\n",
    "    \n",
    "    split_jsonl_dataset(\n",
    "        input_file=FILE_INPUT_ASLI,\n",
    "        output_dir=FOLDER_OUTPUT\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e6b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Membedah file: U_ad025d5c57312a27_clean.TextGrid\n",
      "==================================================\n",
      "Nama Tier: words\n",
      "------------------------------\n",
      "KATA            | MULAI (detik)   | SELESAI (detik)\n",
      "--------------------------------------------------\n",
      "<DIAM>          | 0.0000          | 0.0800\n",
      "right           | 0.0800          | 0.7000\n",
      "<DIAM>          | 0.7000          | 0.9000\n",
      "==================================================\n",
      "Lihat? MFA sudah memberi tahu kita KAPAN tepatnya setiap kata diucapkan!\n"
     ]
    }
   ],
   "source": [
    "import textgrid\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Lokasi hasil MFA Anda tadi\n",
    "MFA_OUTPUT_DIR = \"../data/processed/mfa_aligned_train\"\n",
    "\n",
    "# 1. Ambil satu file TextGrid secara acak\n",
    "all_files = [f for f in os.listdir(MFA_OUTPUT_DIR) if f.endswith('.TextGrid')]\n",
    "random_file = random.choice(all_files)\n",
    "full_path = os.path.join(MFA_OUTPUT_DIR, random_file)\n",
    "\n",
    "print(f\"üïµÔ∏è Membedah file: {random_file}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 2. Baca isinya menggunakan library textgrid\n",
    "tg = textgrid.TextGrid.fromFile(full_path)\n",
    "\n",
    "# 3. TextGrid biasanya punya 2 lapisan (Tier):\n",
    "#    Tier 0 = 'words' (Kata utuh) -> Ini yang kita butuhkan!\n",
    "#    Tier 1 = 'phones' (Fonem/bunyi per huruf: h - a - l - o)\n",
    "\n",
    "words_tier = tg[0] # Mengambil tier kata\n",
    "\n",
    "print(f\"Nama Tier: {words_tier.name}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"{'KATA':<15} | {'MULAI (detik)':<15} | {'SELESAI (detik)':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 4. Loop setiap kata dan waktunya\n",
    "for interval in words_tier:\n",
    "    # MFA menandai diam/silence dengan string kosong \"\" atau \"<sil>\"\n",
    "    kata = interval.mark if interval.mark else \"<DIAM>\"\n",
    "    start = interval.minTime\n",
    "    end = interval.maxTime\n",
    "    \n",
    "    print(f\"{kata:<15} | {start:.4f}          | {end:.4f}\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9454fb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üïµÔ∏è Membedah file: U_c6c6534d417f290c_clean.TextGrid\n",
      "==================================================\n",
      "Nama Tier: words\n",
      "------------------------------\n",
      "KATA            | MULAI (detik)   | SELESAI (detik)\n",
      "--------------------------------------------------\n",
      "<DIAM>          | 0.0000          | 0.0400\n",
      "the             | 0.0400          | 0.1800\n",
      "one             | 0.1800          | 0.5300\n",
      "<DIAM>          | 0.5300          | 0.6000\n",
      "on              | 0.6000          | 0.9600\n",
      "<DIAM>          | 0.9600          | 1.0100\n",
      "the             | 1.0100          | 1.2200\n",
      "right           | 1.2200          | 1.6300\n",
      "<DIAM>          | 1.6300          | 2.1200\n",
      "has             | 2.1200          | 2.4800\n",
      "<DIAM>          | 2.4800          | 2.5500\n",
      "more            | 2.5500          | 3.0300\n",
      "<DIAM>          | 3.0300          | 3.6000\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import textgrid\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Lokasi hasil MFA Anda tadi\n",
    "MFA_OUTPUT_DIR = \"../data/processed/mfa_aligned_train\"\n",
    "\n",
    "# 1. Ambil satu file TextGrid secara acak\n",
    "all_files = [f for f in os.listdir(MFA_OUTPUT_DIR) if f.endswith('.TextGrid')]\n",
    "random_file = random.choice(all_files)\n",
    "full_path = os.path.join(MFA_OUTPUT_DIR, random_file)\n",
    "\n",
    "print(f\"üïµÔ∏è Membedah file: {random_file}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 2. Baca isinya menggunakan library textgrid\n",
    "tg = textgrid.TextGrid.fromFile(full_path)\n",
    "\n",
    "# 3. TextGrid biasanya punya 2 lapisan (Tier):\n",
    "#    Tier 0 = 'words' (Kata utuh) -> Ini yang kita butuhkan!\n",
    "#    Tier 1 = 'phones' (Fonem/bunyi per huruf: h - a - l - o)\n",
    "\n",
    "words_tier = tg[0] # Mengambil tier kata\n",
    "\n",
    "print(f\"Nama Tier: {words_tier.name}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"{'KATA':<15} | {'MULAI (detik)':<15} | {'SELESAI (detik)':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 4. Loop setiap kata dan waktunya\n",
    "for interval in words_tier:\n",
    "    # MFA menandai diam/silence dengan string kosong \"\" atau \"<sil>\"\n",
    "    kata = interval.mark if interval.mark else \"<DIAM>\"\n",
    "    start = interval.minTime\n",
    "    end = interval.maxTime\n",
    "    \n",
    "    print(f\"{kata:<15} | {start:.4f}          | {end:.4f}\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d765b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
